# -*- coding: utf-8 -*-
"""Exercício - Ensembles e KNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/165HSHhNxj1XaZRYgAHpTk5wvl4oq-YON

# Exercício
## Ensembles e K-nearest neighbors
### Alunos (Nome e número usp):
 - Rodolfo Sanches Saraiva Dos Santos, Nusp: 11919606
 - Pedro Regattieri Rocha, Nusp: 8531702
 - Francielle Alves Vargas, Nusp: 9527629
 -
---

Para esse exercício, vamos utilizar novamente o dataset [Breast Cancer Winsconsin](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset).

---

### Questão 1.

Carregue o dataset Breast Cancer do módulo `sklearn.datasets` e normalize os dados.
"""

from sklearn.datasets import load_breast_cancer
from sklearn.preprocessing import scale

X, y = load_breast_cancer(return_X_y=True)
X_scaled = scale(X)

print(X_scaled)
print(y)

"""---

### Questão 2.

Aqui definiremos funções que serão utilizadas para simplificar as operações que faremos posteriormente. Dessa forma, implemente as funções abaixo:

*   A função `get_mean_accuracy(model, X, y)` recebe um modelo `model` e um conjunto de atributos `X` e labels `y`. Ela deve calcular a acurácia do modelo utilizando 10-fold cross-validation estratificado e retornar a acurácia média dos 10 folds
*   A função `evaluate_models(models, X, y)` recebe um conjunto de modelos definidos por um dicionário e exibe, para cada modelo, seu nome seguido da sua acurácia (calculada com a função `get_mean_accuracy`). Um exemplo de saída para o dicionário `exemplo` abaixo seria:
> A acurácia do modelo "Knn (n_neighbors = 5)" é 85.00%
>
> A acurácia do modelo "DT (gini)" é 80.00%

*   Finalmente, implemente a função `create_name_list(models)`. Essa função deve receber um dicionário e retornar uma lista contendo, para cada elemento do dicionário, uma tupla (chave, valor). Para o dicionário `exemplo`, essa função retornaria:
> `[ ('Knn (n_neighbors = 5)', KNeighborsClassifier(n_neighbors=5)), ('DT (gini)', DecisionTreeClassifier(criterion="gini"))]`


```
exemplo = {
    'Knn (n_neighbors = 5)': KNeighborsClassifier(n_neighbors=5),
    'DT (gini)': DecisionTreeClassifier(criterion="gini"),
}
```
"""

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import accuracy_score
import numpy as np

def get_mean_accuracy(model, X, y):
  skf = StratifiedKFold(n_splits=10)
  accuracy_values = []
  for train_index, test_index in skf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test) 
    accuracy_values.append(accuracy_score(y_test, y_pred))
  return np.mean(accuracy_values) 

def evaluate_models(models, X, y):
  for key, model in models.items():
    print("A acurácia do modelo", key, "é %.2f"  % get_mean_accuracy(model, X, y))

def create_name_list(models):
  lista = []
  for key, model in models.items():
    lista.append((key, model))
  return lista

"""---

### Questão 3.

Defina modelos de SVM (`sklearn.svm.SVC`) e MLP (`sklearn.neural_network.MLPClassifier`) para servir de *baseline* de comparação para modelos futuros. Para isso, teste ao menos 3 configurações de SVM e 3 configurações de MLP. Sua baseline será a melhor acurácia (utilizando 10-fold cross-validation estratificado) entre essas configurações. Utilize as funções definidas na Questão 2 quando necessário.
"""

from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
import warnings
warnings.simplefilter("ignore")
#import sys
#sys.setrecursionlimit(500)

experimentos = { 
    "MLP camada escondida (5,)" : MLPClassifier(hidden_layer_sizes=(5,)),
    "MLP camada escondida (5,5)" : MLPClassifier(hidden_layer_sizes=(5,5)),
    "MLP camada escondida (10,)" : MLPClassifier(hidden_layer_sizes=(10,)),
    "SVM sigmoid" : SVC(kernel='sigmoid'),
    "SVM polinomial de grau 4" : SVC(kernel='poly', degree=4),
    "SVM Quadrático" : SVC(kernel='poly', degree=2)
}

evaluate_models(experimentos, X_scaled, y)

"""---

### Questão 4.

Agora defina dois dicionários de classificadores. Um dicionário deve conter apenas classificadores KNN (`sklearn.neighbors.KNeighborsClassifier`), enquanto o outro deve conter apenas classificadores DT (`sklearn.tree.DecisionTreeClassifier`). Crie ao menos 3 configurações diferentes para cada tipo de classificador. Depois calcule e exiba a acurácia de cada configuração criada utilizando 10-fold cross-validation estratificado.
"""

from sklearn.neighbors import KNeighborsClassifier
  from sklearn.tree import DecisionTreeClassifier

  experimentosKNN = {
    "KNN Weight Distance" : KNeighborsClassifier(weights='distance'),
    "KNN 10 neighbors" : KNeighborsClassifier(n_neighbors = 10),
    "KNN Distance 10 neighbors brute force" : KNeighborsClassifier(weights='distance', n_neighbors = 10, algorithm = 'brute')
  }

  experimentosDT = {
      "DT Gini Best" : DecisionTreeClassifier(),
      "DT Gini Random" : DecisionTreeClassifier(splitter = "random"),
      "DT Entropy Best" : DecisionTreeClassifier(criterion = "entropy")
  }

  evaluate_models(experimentosKNN, X_scaled, y)
  evaluate_models(experimentosDT, X_scaled, y)

"""---

### Questão 5.

Agora você deve definir um dicionário contendo diferentes configurações de ensembles a serem testados. Utilize as classes `StackingClassifier`, `AdaBoostClassifier` e `VotingClassifier` do módulo `sklearn.ensemble` (fique a vontade para escolher outros tipos de ensembles desse mesmo módulo). Crie pelo menos 5 configurações diferentes tomando como estimadores os modelos definidos na Questão 4. Calcule a acurácia de cada configuração de ensemble. 

Obs.: Lembre-se de utilizar as funções definidas anteriormente
"""

from sklearn.ensemble import StackingClassifier, VotingClassifier, AdaBoostClassifier

dictJoin = {}
dictJoin.update(experimentosKNN)
dictJoin.update(experimentosDT)

experimentosEnsembles = { 
    "StackingClassifier (experimentosKNN)" : StackingClassifier(estimators=create_name_list(experimentosKNN)),
    "StackingClassifier (experimentosDT)" : StackingClassifier(estimators=create_name_list(experimentosDT)),
    "StackingClassifier (experimentosKNN + experimentosDT)" : StackingClassifier(estimators=create_name_list(dictJoin)),    
    "VotingClassifier (experimentosKNN, soft)" : VotingClassifier(estimators=create_name_list(experimentosKNN), voting='soft'),
    "VotingClassifier (experimentosDT, soft)" : VotingClassifier(estimators=create_name_list(experimentosDT), voting='soft'),
    "VotingClassifier (experimentosDT + experimentosKNN, soft)" : VotingClassifier(estimators=create_name_list(dictJoin), voting='soft'),
    "AdaBoostClassifier(100, 0)" : AdaBoostClassifier(n_estimators=100, random_state=0),
    "AdaBoostClassifier(30, 0)" : AdaBoostClassifier(n_estimators=30, random_state=1)
}

evaluate_models(experimentosEnsembles, X_scaled, y)

"""---

### Questão 6. 

Discuta as acurácias obtidas nas Questões 3, 4 e 5. Houve algum ganho ao utilizar Ensembles? Em qual situação houve maior ganho?

Para os modelos MLP de camada escondida tivemos as melhores acurácias dos experimentos. Para os tamanhos de camada escondida (5,) e (5,5) tivemos acurácia de 0.98, que foram os melhores resultados. Em contrapartida, os piores resultados foram os SVM polinomiais, que tiveram acurácia de 0.8 para o modelo polinomial de grau 4 e 0.82 para o modelo polinomial de grau 2. O modelo Sigmoid teve acurácia bem maior, 0.96.

Para os modelos KNN, a acurácia de todos os três modelos testados foram 0.97.
Decision Tree teve uma acurácia um pouco menor, variando de 0.91 para a função padrão (Gini criterion, Best Splitter) até 0.94 (Entropy criterion, Random Splitter).

No caso dos Ensembles, houve ganho no caso dos Decision Tree Classifiers, em que a acurácia foi de 0.94 no melhor caso (Entropy criterion, Random Splitter) para 0.95 no Voting Classifier.
"""