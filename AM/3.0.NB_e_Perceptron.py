# -*- coding: utf-8 -*-
"""Exercício - NB e Perceptron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1S0lb5Dk2PCBiadxo1huKtoOXwx6Brmb_

# Exercício
## Naive-Bayes e Perceptron
### Alunos (Nome e número usp):
 - Rodolfo Sanches Saraiva Dos Santos, Nusp: 11919606
 - Pedro Regattieri Rocha, Nusp: 8531702
 - Francielle Alves Vargas, Nusp: 9527629
---

```
# This is formatted as code
```

Para esse exercício será utilizado um conjunto de imagens de dois caracteres, "V" normal e "V" invertido. As imagems possuem dimensão 30x30 e estão em escala de cinza. Cada imagem é representada por uma linha no conjunto de dados (a imagem 30x30 foi transformada em um vetor 1x900). A última coluna desse conjunto representa a classe da imagem, sendo que o valor 0 corresponde ao caractere "V", e 1 ao "V" invertido.

---

### Questão 1. 

Carregue o arquivo "data.npy" utilizando a biblioteca `numpy` e mostre a imagem de número 0 e a imagem de número 10 utilizando a função `imshow()` da biblioteca `matplotlib`. Note que você deve redimensionar a imagem para seu formato original para usar essa função.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from matplotlib import pyplot as plt
# %matplotlib inline

# Array de 16x901
imagens = np.load('data.npy')

firstImage = imagens[0][0:900].reshape(30, 30)
tenthImage = imagens[10][0:900].reshape(30, 30)

plt.imshow(firstImage) 
plt.show()

plt.imshow(tenthImage) 
plt.show()

"""---

### Questão 2.

Separe o conjunto em 75% treino e 25% teste. Utilize o parâmetro `stratify=y`, onde `y` representa seu conjunto de classes.
"""

from sklearn.model_selection import train_test_split

X = imagens[:,:-1]
y = imagens[:,-1:]

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,stratify=y)

print("X_train:")
print(X_train)
print("X_test:")
print(X_test)
print("Y_train:")
print(y_train)
print("Y_test:")
print(y_test)

"""---
### Questão 3.

Treine os classificadores `Perceptron` e `GaussianNB` no conjunto de treino e exiba suas acurácias no conjunto de teste.
"""

from sklearn.linear_model import Perceptron
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

perceptron = Perceptron()
perceptron.fit(X_train, y_train.reshape(-1)) 

y_pred = perceptron.predict(X_test)

print("Predict:")
print(y_pred)
print("True:")
print(y_test.reshape(-1))
accuracy = accuracy_score(y_test.reshape(-1), y_pred) 
print("Accuracy: %.2f%%" % (accuracy*100))

NB = GaussianNB()
NB.fit(X_train, y_train.reshape(-1)) 

y_pred = NB.predict(X_test)

print("Predict:")
print(y_pred)
print("True:")
print(y_test.reshape(-1))
accuracy = accuracy_score(y_test.reshape(-1), y_pred) 
print("Accuracy: %.2f%%" % (accuracy*100))

"""---
### Questão 4.

Crie um conjunto de testes carregando os arquivos `0.png`, `1.png`, `2.png` e `3.png`. Para isso, utilize a função `imread()` passando como parâmetro `as_gray=True`. Seu conjunto final deve possuir dimensões (4, 900), ou seja, 4 observações de tamanho 900.
"""

import numpy as np
from skimage.io import imread

image1 = imread('0.png', as_gray=True).reshape(-1)
image2 = imread('1.png', as_gray=True).reshape(-1)
image3 = imread('2.png', as_gray=True).reshape(-1)
image4 = imread('3.png', as_gray=True).reshape(-1)


Z = np.array([image1, image2, image3, image4])

"""---

### Questão 5.

Teste os classificadores treinados no conjunto de testes que você criou e calcule a acurácia.
"""

z_true = [0,1,1,0]

print("---- Perceptron ----")
z_pred = perceptron.predict(Z) 
print("Predict:")
print(z_pred)
print("True:")
print(z_true) 
accuracy = accuracy_score(z_true, z_pred) 
print("Accuracy: %.2f%%" % (accuracy*100))


print("---- Gaussian NB ----")
z_pred = NB.predict(Z) 
print("Predict:")
print(z_pred)
print("True:")
print(z_true) 
accuracy = accuracy_score(z_true, z_pred) 
print("Accuracy: %.2f%%" % (accuracy*100))

"""---

### Questão 6.
Agora você deve calcular e exibir a confiança dos classificadores para o conjunto que você criou. Para o caso do `Perceptron`, podemos calcular a distância da classe ao hiperplano separador (isso pode ser feito utilizando-se a função membro `decision_function()`). Para o `GaussianNB`, utiliza-se o vetor de probabilidades para cada exemplo (isso pode ser feito utilizando-se a função membro `predict_proba()`). 

Comente a relação entre o valor da distância/probabilidades e a "incerteza" de um classificador. Em outras palavras, o que poderíamos observar nesses valores caso nosso classificador fosse incerto? Comente tanto para o caso do `GaussianNB` quanto para o `Perceptron`.
"""

print(perceptron.decision_function(Z))
print(NB.predict_proba(Z))

"""No caso do Perceptron, os valores das distâncias ficam razoavelmente próximas do hiperplano separador, com uma classificador incerto, as distâncias tendem a aumentar.

No caso do GaussianNB, o classificador utilizado deu 100% de certeza para classificar as classes, com um classificador incerto, as probabilidades iriam mudar, como por exemplo: 60% para classe 1 e 40% para classe 2. [0.6  0.4]
"""