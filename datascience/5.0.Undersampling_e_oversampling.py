# -*- coding: utf-8 -*-
"""Undersampling e Oversampling.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/142szWPbN38t0BI93D56l5WgLNMQqmJ_z

# Undersampling e Oversampling no Pandas

Desbalanceamento de dados é um problema muito comum nos conjuntos de dados. Duas possíveis soluções são a subamostragem (undersampling) aleatória e a superamostragem (oversampling) aleatória. O exemplo a seguir mostra um exemplo simples de como isso pode ser feito utilizando a biblioteca Pandas.

---

## Exploração inicial dos dados:

Criando conjunto de dados artificial, desbalanceado:
"""

from matplotlib import pyplot as plt
import pandas as pd
import numpy as np
# Dados de exemplo
dados = pd.DataFrame({
    'idade': np.round(np.random.normal(loc=30, scale=10, size=1000)),
    'sexo': np.random.choice([0, 1], 1000), # 0 homem, 1 mulher
    'altura': np.round(np.random.normal(loc=1.6, scale=.15, size=1000), 2),
    'classe':  np.random.choice([0, 1], 1000, p=[0.05, 0.95])
    })

plt.rcParams['figure.figsize'] = [15, 10]
dados.hist()

"""Nota-se um grande desbalanceamento das classes através do histograma da variável alvo `classe`"""

dados['classe'].value_counts()

"""A função `value_counts()` confirma o desbalanceamento: há **955** ocorrências da classe 1 e apenas **45** da classe 0.

---

## Superamostragem - Oversampling

Na superamostragem vamos aumentar o número de elementos da classe menos representada.

Primeiro vamos separar as tuplas do nosso conjunto de dados em que a classe é igual à 0:
"""

classe_0 = dados[dados.classe == 0]
classe_0

classe_0.shape

"""Agora vamos obter uma amostra de tamanho **955**, para que as classes fiquem igualmente distribuídas. Note que `replace` deve ser true, pois sem repetições não conseguiriamos criar uma amostra da classe `0` maior que **45**:"""

sample_0 = classe_0.sample(n=955, replace=True)
sample_0

"""Agora vamos concatenar os dados da nossa amostra com os dados do conjunto original que possuiam classe igual à 1:"""

classe_1 = dados[dados.classe == 1]
dados_upsampled = pd.concat([sample_0, classe_1])
dados_upsampled

"""Checando a distribuição das classes:"""

dados_upsampled.hist('classe')

dados_upsampled['classe'].value_counts()

dados_upsampled.hist()

"""---

## Subamostragem - Undersampling

Para a subamostragem, vamos diminuir o tamanho da classe predominante.

Checando a distribuição das classes nos dados originais:
"""

dados['classe'].value_counts()

"""Selecionando as tuplas em que a classe é igual à 1:"""

classe_1 = dados[dados.classe == 1]
classe_1

"""Obtendo uma amostra de tamanho **45**. Note que, nesse caso, é interessante que nossa amostra possua elementos distintos, por isso `replace=False`:"""

sample_1 = classe_1.sample(n=45, replace=False)
sample_1

sample_1.shape

"""Agora iremos concatenar a amostra com dados com os dados do conjunto original que possuiam classe igual a `0`:"""

classe_0 = dados[dados.classe == 0]
dados_downsampled = pd.concat([classe_0, sample_1])

"""Verificando a distribuição das classes:"""

dados_downsampled.hist('classe')

dados_downsampled['classe'].value_counts()

dados_downsampled.hist()

"""---

## Métricas de desempenho em conjuntos desbalanceados

Alguns cuidados são necessários ao medir desempenho em dados não balanceados. Por exemplo, suponha um classificador binário (`Some_classifier`) que sempre classifica uma entrada como a classe predominante do conjunto. Vamos calcular sua acurácia no conjunto de dados inicial:
"""

import numpy as np

# Criando uma classe de classificador de exemplo
class Some_classifier:
  def __init__(self):
    self.predict_value = None
  def fit(self, X, y):
    self.predict_value = y.mode()
  def predict(self, X):
    return np.repeat(1, X.shape[0])

"""Separando em variáveis de entrada (`X`) e variáveis alvo (`y`) e calculando acurácia padrão:"""

from sklearn.metrics import accuracy_score

# Separando o conjunto de dados
X, y = dados.iloc[:, :-1], dados.iloc[:, -1]

my_classifier = Some_classifier()
my_classifier.fit(X, y)
y_pred = my_classifier.predict(X)

print("Acurácia do classificador: %.2f%%" % (accuracy_score(y, y_pred)*100))

"""A medida de acurácia não representa muito bem o desempenho do nosso classificador. Existem métricas melhores:"""

from sklearn.metrics import balanced_accuracy_score

print("Acurácia balanceada do classificador: %.2f%%" % (balanced_accuracy_score(y, y_pred)*100))

print("Acurácia balanceada (ajustada para caso aleatório) do classificador: %.2f%%" % (balanced_accuracy_score(y, y_pred, adjusted=True)*100))

from sklearn.metrics import precision_score

print("Precisão média-macro do classificador: %.2f%%" % (precision_score(y, y_pred,labels=[0, 1], average='macro', zero_division=0)*100))

"""Material que discute bem diferentes métricas para dados desbalanceados: https://machinelearningmastery.com/tour-of-evaluation-metrics-for-imbalanced-classification/"""